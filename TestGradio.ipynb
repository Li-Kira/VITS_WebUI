{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cRKuRl7Z8Nj"
   },
   "source": [
    "# Requirment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ouQGqsHfsDv6",
    "outputId": "8a464347-c2ba-489e-8f45-3707e9ba2e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\AI\\VITS_WebUI\\monotonic_align\n",
      "running build_ext\n",
      "copying build\\lib.win-amd64-3.9\\monotonic_align\\core.cp39-win_amd64.pyd -> monotonic_align\n",
      "G:\\AI\\VITS_WebUI\n"
     ]
    }
   ],
   "source": [
    "%cd G:\\AI\\VITS_WebUI\\monotonic_align\n",
    "!python setup.py build_ext --inplace\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  3 13:57:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060       WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   29C    P8               19W / 170W|   5118MiB / 12288MiB |     17%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4696    C+G   ...277.0_x64__dt26b99r8h8gj\\RtkUWP.exe    N/A      |\n",
      "|    0   N/A  N/A      7328    C+G   D:\\PotPlayer\\PotPlayerMini64.exe          N/A      |\n",
      "|    0   N/A  N/A      8556    C+G   D:\\Eagle\\Eagle.exe                        N/A      |\n",
      "|    0   N/A  N/A      8588    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10360    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10968    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     11220    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A     12252    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13060    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13708    C+G   ...rPicker\\PowerToys.ColorPickerUI.exe    N/A      |\n",
      "|    0   N/A  N/A     13732    C+G   ...FancyZones\\PowerToys.FancyZones.exe    N/A      |\n",
      "|    0   N/A  N/A     13832    C+G   ...auncher\\PowerToys.PowerLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     14668    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14888    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     15296    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     15512    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15564    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17232    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     17720    C+G   ...03.0_x64__8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     18288    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     18480    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     18496    C+G   ...0.0_x64__p7pnf6hceqser\\snipaste.exe    N/A      |\n",
      "|    0   N/A  N/A     18780    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     20072    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     22432    C+G   D:\\motrix\\Motrix.exe                      N/A      |\n",
      "|    0   N/A  N/A     23388    C+G   D:\\Typora\\Typora.exe                      N/A      |\n",
      "|    0   N/A  N/A     24948    C+G   ...-ins\\Spaces\\Adobe Spaces Helper.exe    N/A      |\n",
      "|    0   N/A  N/A     26396    C+G   D:\\CloudMusic\\cloudmusic.exe              N/A      |\n",
      "|    0   N/A  N/A     29556    C+G   ...obe Photoshop CC 2019\\Photoshop.exe    N/A      |\n",
      "|    0   N/A  N/A     31416    C+G   ...CEP\\CEPHtmlEngine\\CEPHtmlEngine.exe    N/A      |\n",
      "|    0   N/A  N/A     31424    C+G   ...CEP\\CEPHtmlEngine\\CEPHtmlEngine.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxpEIauJZ0s6"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "v10x1lO7Z5AK"
   },
   "outputs": [],
   "source": [
    "#@title  Edit config\n",
    "import json\n",
    "batchsize = 16  #@param {type:\"number\"}\n",
    "training_files = \"filelists/yuuka_train.txt.cleaned\" #@param {type:\"string\"}\n",
    "validation_files = \"filelists/yuuka_val.txt.cleaned\" #@param {type:\"string\"}\n",
    "config = json.load(open(\"configs/config.json\"))\n",
    "config['train']['batch_size'] = batchsize\n",
    "config['data']['training_files'] = training_files\n",
    "config['data']['validation_files'] = validation_files\n",
    "with open(\"configs/config.json\", 'w+') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBNba8Qpa7XF"
   },
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zF5IUSAQa_EB"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gcO8hd1Jr2t6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import commons\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "from scipy.io.wavfile import write\n",
    "from gradio.processing_utils import download_tmp_copy_of_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nk7e6dxxrzWq"
   },
   "outputs": [],
   "source": [
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rCka4asRScyC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'G:\\AI\\Model\\VITS\\Yuuka\\G_4000.pth' (iteration 445)\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/config.json\" \n",
    "model_path = \"G:\\AI\\Model\\VITS\\Yuuka\\G_4000.pth\"\n",
    "\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "\n",
    "model = net_g.eval()\n",
    "model = utils.load_checkpoint(model_path, net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tp-8n_YBg5FN"
   },
   "outputs": [],
   "source": [
    "LANGUAGES = ['EN','CN','JP']\n",
    "speaker_id = 0\n",
    "cover = \"models/Yuuka/cover.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mika\n"
     ]
    }
   ],
   "source": [
    "with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    models_info = json.load(f)\n",
    "\n",
    "for i,model_info in models_info.items():\n",
    "    name_en = model_info['name_en']\n",
    "\n",
    "print(name_en)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(models_info['yuuka']['sid'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yxBbm6Yh8WkH"
   },
   "outputs": [],
   "source": [
    "download_audio_js = \"\"\"\n",
    "() =>{{\n",
    "    let root = document.querySelector(\"body > gradio-app\");\n",
    "    if (root.shadowRoot != null)\n",
    "        root = root.shadowRoot;\n",
    "    let audio = root.querySelector(\"#tts-audio-{audio_id}\").querySelector(\"audio\");\n",
    "    let text = root.querySelector(\"#input-text-{audio_id}\").querySelector(\"textarea\");\n",
    "    if (audio == undefined)\n",
    "        return;\n",
    "    text = text.value;\n",
    "    if (text == undefined)\n",
    "        text = Math.floor(Math.random()*100000000);\n",
    "    audio = audio.src;\n",
    "    let oA = document.createElement(\"a\");\n",
    "    oA.download = text.substr(0, 20)+'.wav';\n",
    "    oA.href = audio;\n",
    "    document.body.appendChild(oA);\n",
    "    oA.click();\n",
    "    oA.remove();\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tts_fn(text, noise_scale, noise_scale_w, length_scale):\n",
    "  stn_tst = get_text(text, hps)\n",
    "  with torch.no_grad():\n",
    "    x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "    sid = torch.LongTensor([speaker_id]).cuda()\n",
    "    audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=noise_scale, noise_scale_w=noise_scale_w, length_scale=length_scale)[0][0,0].data.cpu().float().numpy()\n",
    "  return  (22050, audio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "\n",
    "def add_model_fn(model_path, Image, SpeakerID, name_en, name_cn, language):\n",
    "\n",
    "    #获取用户输入\n",
    "    new_model = {\n",
    "        \"name_en\": name_en,\n",
    "        \"name_zh\": name_cn,\n",
    "        \"cover\": Image,\n",
    "        \"sid\": SpeakerID,\n",
    "        \"example\": \"それに新しいお菓子屋さんも出来てみんな買いものを楽しんでいます！\",\n",
    "        \"language\": language,\n",
    "        \"type\": \"single\",\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "\n",
    "    # 检查必填字段是否为空\n",
    "    if not file.data or not speaker_id or not name_en or not language:\n",
    "        gr.Interface.error(\"Please fill in all required fields!\")\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 保存上传的文件\n",
    "    file_data = file.data[0]\n",
    "    filename = secure_filename(file_data.name)\n",
    "    filepath = os.path.join(\"models\", name_en, filename)\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "\n",
    "    with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        models_info = json.load(f)\n",
    "\n",
    "    models_info[name_en] = new_model\n",
    "    with open(\"models.json\", \"w\") as f:\n",
    "        json.dump(models_info, f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.reference:entering reference: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ML\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'scale': 2}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'fn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 35\u001B[0m\n\u001B[0;32m     32\u001B[0m             output_audio \u001B[38;5;241m=\u001B[39m gr\u001B[38;5;241m.\u001B[39mAudio(label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOutput\u001B[39m\u001B[38;5;124m\"\u001B[39m, elem_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtts-audio-en-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname_en\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     33\u001B[0m             download_button \u001B[38;5;241m=\u001B[39m gr\u001B[38;5;241m.\u001B[39mButton(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownload\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 35\u001B[0m \u001B[43mclear_input_button\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclick\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m gen_button\u001B[38;5;241m.\u001B[39mclick(\n\u001B[0;32m     37\u001B[0m             tts_fn,\n\u001B[0;32m     38\u001B[0m             inputs \u001B[38;5;241m=\u001B[39m [input_text, noise_scale, noise_scale_w, length_scale],\n\u001B[0;32m     39\u001B[0m             outputs \u001B[38;5;241m=\u001B[39m output_audio)\n\u001B[0;32m     40\u001B[0m download_button\u001B[38;5;241m.\u001B[39mclick(\u001B[38;5;28;01mNone\u001B[39;00m, [], [], _js\u001B[38;5;241m=\u001B[39mdownload_audio_js\u001B[38;5;241m.\u001B[39mformat(audio_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname_en\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mTypeError\u001B[0m: __call__() missing 1 required positional argument: 'fn'"
     ]
    }
   ],
   "source": [
    "theme = gr.themes.Base()\n",
    "\n",
    "with gr.Blocks(theme=theme) as interface:\n",
    "    with gr.Tab(\"Text to Speech\"):\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{cover}\">' if cover else \"\"\n",
    "                                                                                           '</div>')\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 4):\n",
    "                    input_text = gr.Textbox(\n",
    "                        label=\"Input\",\n",
    "                        lines=2,\n",
    "                        placeholder=\"Enter the text you want to process here\",\n",
    "                        elem_id=f\"input-text-en-{name_en.replace(' ','')}\",\n",
    "                        scale = 2\n",
    "                    )\n",
    "                with gr.Column(scale = 1):\n",
    "                    gen_button = gr.Button(\"Generate\", variant=\"primary\")\n",
    "                    clear_input_button = gr.Button(\"Clear\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 2):\n",
    "                    lan = [gr.Radio(label=\"Language\", choices=LANGUAGES, value=\"JP\")]\n",
    "                    noise_scale = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale (情感变化程度)\", value = 0.6)\n",
    "                    noise_scale_w = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale w (发音长度)\", value = 0.668)\n",
    "                    length_scale = gr.Slider(minimum=0.1, maximum=2.0, step=0.1, label = \"Length Scale (语速)\", value=1.0)\n",
    "\n",
    "                with gr.Column(scale = 1):\n",
    "                    output_audio = gr.Audio(label=\"Output\", elem_id=f\"tts-audio-en-{name_en.replace(' ','')}\")\n",
    "                    download_button = gr.Button(\"Download\")\n",
    "\n",
    "        #clear_input_button.click()\n",
    "        gen_button.click(\n",
    "                    tts_fn,\n",
    "                    inputs = [input_text, noise_scale, noise_scale_w, length_scale],\n",
    "                    outputs = output_audio)\n",
    "        download_button.click(None, [], [], _js=download_audio_js.format(audio_id=f\"en-{name_en.replace(' ', '')}\"))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"AI Singer\"):\n",
    "        input_text_singer = gr.Textbox()\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"TTS with ChatGPT\"):\n",
    "        input_text_gpt = gr.Textbox()\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"Settings\"):\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"\"\"# Select Model\"\"\")\n",
    "            with gr.Row():\n",
    "                model_choice = gr.Dropdown(label = \"Model\",\n",
    "                                           choices=[(model[\"name_en\"]) for name, model in models_info.items()],\n",
    "                                           interactive=True,\n",
    "                                           value=models_info['yuuka']['name_en']\n",
    "                                         )\n",
    "                speaker_id = gr.Dropdown(label = \"Speaker ID\",\n",
    "                                         choices=[(str(model[\"sid\"])) for name, model in models_info.items()],\n",
    "                                         interactive=True,\n",
    "                                         value=str(models_info['yuuka']['sid'])\n",
    "                                         )\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"# Add Model\\n\"\n",
    "                        \"> *为必填选项\"\n",
    "                        )\n",
    "\n",
    "\n",
    "            with gr.Row():\n",
    "                file = gr.Files(label = \"VITS Model*\")\n",
    "                model_cover = gr.Image()\n",
    "\n",
    "                with gr.Column():\n",
    "                    model_speaker_id = gr.Textbox(label = \"Speaker List*\",\n",
    "                                                  placeholder=\"Single speaker model default=0\")\n",
    "                    model_name_en = gr.Textbox(label = \"name_en*\")\n",
    "                    model_name_cn = gr.Textbox(label = \"name_cn\")\n",
    "                    model_language = gr.Dropdown(label = \"Language*\",\n",
    "                                               choices=LANGUAGES,\n",
    "                                               interactive=True)\n",
    "                    with gr.Row():\n",
    "                        add_model_button = gr.Button(\"Add Model\", variant=\"primary\")\n",
    "                        clear_add_model_button = gr.Button(\"Clear\")\n",
    "\n",
    "        add_model_button.click(add_model_fn,\n",
    "                               inputs = [file, model_cover, model_speaker_id, model_name_en, model_name_cn, model_language]\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interface.queue(concurrency_count=1).launch()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     15\u001B[0m         json\u001B[38;5;241m.\u001B[39mdump(models, f)\n\u001B[1;32m---> 17\u001B[0m model_names \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m, in \u001B[0;36mget_model_names\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_model_names\u001B[39m():\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      4\u001B[0m         models \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(models\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m     )\n\u001B[1;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'models.json'"
     ]
    }
   ],
   "source": [
    "# 定义函数，用于从 json 文件中读取所有模型的名称\n",
    "def get_model_names():\n",
    "    with open(\"models.json\", \"r\") as f:\n",
    "        models = json.load(f)\n",
    "    return list(models.keys())\n",
    "\n",
    "\n",
    "\n",
    "# 定义函数，用于向 json 文件中添加一个新的模型\n",
    "def add_model(model_name, model_info):\n",
    "    with open(\"models.json\", \"r\") as f:\n",
    "        models = json.load(f)\n",
    "    models[model_name] = model_info\n",
    "    with open(\"models.json\", \"w\") as f:\n",
    "        json.dump(models, f)\n",
    "\n",
    "model_names = get_model_names()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QV-KjNxeqTdj"
   },
   "outputs": [],
   "source": [
    "css_style = \"\"\"\n",
    "    .gradio-input { grid-area: input; }\n",
    "    .gradio-output { grid-area: output; }\n",
    "    .gradio-control { grid-area: control; }\n",
    "    .gradio-interface { \n",
    "        display: grid;\n",
    "        grid-template-columns: 1fr 1fr;\n",
    "        grid-template-rows: 1fr auto;\n",
    "        grid-template-areas: \n",
    "            \"input input\"\n",
    "            \"control output\";\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9-zq-AHsNIR"
   },
   "source": [
    "# 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH1u_QQpqGd2"
   },
   "outputs": [],
   "source": [
    "config_path = \"configs/config.json\" #@param {type:\"string\"}\n",
    "model_path = \"../drive/MyDrive/vits-finetune/checkpoints/G_4000.pth\" #@param {type:\"string\"}\n",
    "\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "\n",
    "model = net_g.eval()\n",
    "model = utils.load_checkpoint(model_path, net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1678279239275,
     "user": {
      "displayName": "Light Kira",
      "userId": "14953510812850181711"
     },
     "user_tz": -480
    },
    "id": "p3amgR8AKvcF",
    "outputId": "fa4ff32d-59a2-4f99-8263-dd4036e98a03"
   },
   "outputs": [],
   "source": [
    "speaker_id = 0 #@param {type:\"number\"}\n",
    "text = \"\\u30CB\\u30B8\\u30E7\\u30B9\\u30B0\\u30B8\\u30D0\\uFF0C\\u30D3\\u30A8\\u30B6\\u30A4\\u30BC\\u30EA\\u30D5\\u30A1\\u30C7\\u30F3\\u5148\\u751F\\u3002\" #@param {type:\"string\"}\n",
    "noise_scale=0.7 #@param {type:\"number\"}\n",
    "noise_scale_w=0.668 #@param {type:\"number\"}\n",
    "length_scale=1.0 #@param {type:\"number\"}\n",
    "stn_tst = get_text(text, hps)\n",
    "with torch.no_grad():\n",
    "    x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "    sid = torch.LongTensor([speaker_id]).cuda()\n",
    "    audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=noise_scale, noise_scale_w=noise_scale_w, length_scale=length_scale)[0][0,0].data.cpu().float().numpy()\n",
    "\n",
    "ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dImJ80XAawR8"
   },
   "outputs": [],
   "source": [
    "def text_to_speech(x):\n",
    "    return x[::-1]\n",
    "\n",
    "\n",
    "def flip_image(x):\n",
    "    return np.fliplr(x)\n",
    "\n",
    "with gr.Blocks() as interface:\n",
    "    with gr.Tab(\"Text to Speech\"):\n",
    "        text_input = gr.Textbox(lines=5, placeholder=\"Enter the text you want to process here\")\n",
    "        text_output = gr.Textbox()\n",
    "        text_button = gr.Button(\"Flip\")\n",
    "    with gr.Tab(\"Flip Image\"):\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image()\n",
    "            image_output = gr.Image()\n",
    "        image_button = gr.Button(\"Flip\")\n",
    "\n",
    "    text_button.click(text_to_speech, inputs=text_input, outputs=text_output)\n",
    "    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE-Acz0rc6ZM"
   },
   "outputs": [],
   "source": [
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOanTxjuTkrY9G5Z/F1JKYD",
   "collapsed_sections": [
    "1cRKuRl7Z8Nj",
    "uYQ2esCNI4IT",
    "YvWwpaTKI5Ut",
    "1rerX8gxPmLf",
    "vs-wM321Zk0u",
    "SxpEIauJZ0s6"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
