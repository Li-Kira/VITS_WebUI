{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ouQGqsHfsDv6",
    "outputId": "8a464347-c2ba-489e-8f45-3707e9ba2e1d"
   },
   "outputs": [],
   "source": [
    "%cd G:\\AI\\VITS_WebUI\\monotonic_align\n",
    "!python setup.py build_ext --inplace\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxpEIauJZ0s6"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "v10x1lO7Z5AK"
   },
   "outputs": [],
   "source": [
    "#@title  Edit config\n",
    "import json\n",
    "batchsize = 16  #@param {type:\"number\"}\n",
    "training_files = \"filelists/yuuka_train.txt.cleaned\" #@param {type:\"string\"}\n",
    "validation_files = \"filelists/yuuka_val.txt.cleaned\" #@param {type:\"string\"}\n",
    "config = json.load(open(\"configs/config.json\"))\n",
    "config['train']['batch_size'] = batchsize\n",
    "config['data']['training_files'] = training_files\n",
    "config['data']['validation_files'] = validation_files\n",
    "with open(\"configs/config.json\", 'w+') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBNba8Qpa7XF"
   },
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcO8hd1Jr2t6"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import commons\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import openai\n",
    "import gradio as gr\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tp-8n_YBg5FN"
   },
   "outputs": [],
   "source": [
    "LANGUAGES = ['EN','CN','JP']\n",
    "SELECTED_LANGUAGE = \"JP\"\n",
    "SPEAKER_ID = 0\n",
    "COVER = \"models/Yuuka/cover.png\"\n",
    "speaker_choice = \"Yuuka\"\n",
    "MODEL_ZH_NAME = \"早濑优香\"\n",
    "EXAMPLE_TEXT = \"先生。今日も全力であなたをアシストしますね。\"\n",
    "USER_INPUT_TEXT = \"\"\n",
    "\n",
    "CONFIG_PATH = \"configs/config.json\"\n",
    "MODEL_PATH = \"models/Yuuka/Yuuka.pth\"\n",
    "\n",
    "\n",
    "\n",
    "hps = utils.get_hparams_from_file(CONFIG_PATH)\n",
    "net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "\n",
    "model = net_g.eval()\n",
    "model = utils.load_checkpoint(MODEL_PATH, net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_text(text, hps):\n",
    "    text_norm, clean_text = text_to_sequence(text, hps.symbols, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm, clean_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limitation = os.getenv(\"SYSTEM\") == \"spaces\"\n",
    "\n",
    "def tts_fn(text, noise_scale, noise_scale_w, length_scale):\n",
    "    if not len(text):\n",
    "        return \"输入文本不能为空！\", None, None\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').replace(\" \", \"\")\n",
    "    if len(text) > 100 and limitation:\n",
    "        return f\"输入文字过长！{len(text)}>100\", None, None\n",
    "    if SELECTED_LANGUAGE == \"JP\":\n",
    "      text = f\"[JA]{text}[JA]\"\n",
    "    if SELECTED_LANGUAGE == \"CN\":\n",
    "      text = f\"[ZH]{text}[ZH]\"\n",
    "\n",
    "\n",
    "    stn_tst, clean_text = get_text(text, hps)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "        sid = torch.LongTensor([SPEAKER_ID]).cuda()\n",
    "        audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=noise_scale, noise_scale_w=noise_scale_w,\n",
    "                               length_scale=length_scale)[0][0, 0].data.cpu().float().numpy()\n",
    "\n",
    "    return (22050, audio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    models_info = json.load(f)\n",
    "\n",
    "for i,model_info in models_info.items():\n",
    "    name_en = model_info['name_en']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    global hps,net_g,model\n",
    "\n",
    "    hps = utils.get_hparams_from_file(CONFIG_PATH)\n",
    "    net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "\n",
    "    model = net_g.eval()\n",
    "    model = utils.load_checkpoint(MODEL_PATH, net_g, None)\n",
    "\n",
    "\n",
    "def add_model_fn(example_text, cover, speakerID, name_en, name_cn, language):\n",
    "\n",
    "    # 检查必填字段是否为空\n",
    "    if not speakerID or not name_en or not language:\n",
    "        raise gr.Error(\"Please fill in all required fields!\")\n",
    "        return \"Failed to add model\"\n",
    "\n",
    "    ### 保存上传的文件\n",
    "\n",
    "    # 生成文件路径\n",
    "    model_save_dir = Path(\"models\")\n",
    "    model_save_dir = model_save_dir / name_en\n",
    "    img_save_dir = model_save_dir\n",
    "    model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    Model_name = name_en + \".pth\"\n",
    "    model_save_dir = model_save_dir / Model_name\n",
    "\n",
    "    # 保存上传的图片\n",
    "    if cover is not None:\n",
    "        img = np.array(cover)\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(os.path.join(img_save_dir, 'cover_white_background.png'))\n",
    "\n",
    "    #获取用户输入\n",
    "    new_model = {\n",
    "        \"name_en\": name_en,\n",
    "        \"name_zh\": name_cn,\n",
    "        \"cover\": img_save_dir / \"cover.png\",\n",
    "        \"sid\": speakerID,\n",
    "        \"example\": example_text,\n",
    "        \"language\": language,\n",
    "        \"type\": \"single\",\n",
    "        \"model_path\": model_save_dir\n",
    "    }\n",
    "\n",
    "    #写入json\n",
    "    with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        models_info = json.load(f)\n",
    "\n",
    "    models_info[name_en] = new_model\n",
    "    with open(\"models/model_info.json\", \"w\") as f:\n",
    "        json.dump(models_info, f, cls=CustomEncoder)\n",
    "\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "\n",
    "def clear_input_text():\n",
    "    return \"\"\n",
    "\n",
    "def clear_add_model_info():\n",
    "    return \"\",None,\"\",\"\",\"\",\"\"\n",
    "\n",
    "def get_options():\n",
    "  with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    global models_info\n",
    "    models_info = json.load(f)\n",
    "\n",
    "  for i,model_info in models_info.items():\n",
    "    global name_en\n",
    "    name_en = model_info['name_en']\n",
    "\n",
    "\n",
    "def reset_options():\n",
    "  value_model_choice = models_info['Yuuka']['name_en']\n",
    "  value_speaker_id = models_info['Yuuka']['sid']\n",
    "  return value_model_choice,value_speaker_id\n",
    "\n",
    "def refresh_options():\n",
    "  get_options()\n",
    "  value_model_choice = models_info[speaker_choice]['name_en']\n",
    "  value_speaker_id = models_info[speaker_choice]['sid']\n",
    "  return value_model_choice,value_speaker_id\n",
    "\n",
    "def change_dropdown(choice):\n",
    "  global speaker_choice\n",
    "  speaker_choice = choice\n",
    "  global COVER\n",
    "  COVER = str(models_info[speaker_choice]['cover'])\n",
    "  global MODEL_PATH\n",
    "  MODEL_PATH = str(models_info[speaker_choice]['model_path'])\n",
    "  global MODEL_ZH_NAME\n",
    "  MODEL_ZH_NAME = str(models_info[speaker_choice]['name_zh'])\n",
    "  global EXAMPLE_TEXT\n",
    "  EXAMPLE_TEXT = str(models_info[speaker_choice]['example'])\n",
    "  global SELECTED_LANGUAGE\n",
    "  SELECTED_LANGUAGE = str(models_info[speaker_choice]['language'])\n",
    "\n",
    "  speaker_id_change = gr.update(value=str(models_info[speaker_choice]['sid']))\n",
    "  cover_change = gr.update(value='<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\"\n",
    "                f'<a><strong>{speaker_choice}</strong></a>'\n",
    "                                                                                           '</div>')\n",
    "  title_change = gr.update(value=\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>'\n",
    "                                                                                           '</div>')\n",
    "\n",
    "\n",
    "  lan_change = gr.update(value=str(models_info[speaker_choice]['language']))\n",
    "\n",
    "  example_change = gr.update(value=EXAMPLE_TEXT)\n",
    "\n",
    "  VC_cover_change = gr.update(value=\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\")\n",
    "\n",
    "  VC_title_change = gr.update(value=\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>')\n",
    "\n",
    "  ChatGPT_cover_change = gr.update(value='<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\"\n",
    "                f'<a><strong>{speaker_choice}</strong></a>'\n",
    "                                                                                           '</div>')\n",
    "  ChatGPT_title_change = gr.update(value=\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>'\n",
    "                                                                                           '</div>')\n",
    "\n",
    "  load_model()\n",
    "\n",
    "  return [speaker_id_change,cover_change,title_change,lan_change,example_change,cover_change,title_change,lan_change,cover_change,title_change]\n",
    "\n",
    "\n",
    "def load_api_key(value):\n",
    "  openai.api_key = value\n",
    "\n",
    "def usr_input_update(value):\n",
    "  global USER_INPUT_TEXT\n",
    "  USER_INPUT_TEXT = value\n",
    "\n",
    "\n",
    "# def ChatGPT_Bot(history):\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#       model=\"gpt-3.5-turbo\",\n",
    "#       messages=[\n",
    "#           {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#           {\"role\": \"user\", \"content\": history}\n",
    "#         ]\n",
    "#     )\n",
    "#     text = response['choices'][0]['message']['content']\n",
    "\n",
    "#     audio = tts_fn(text, 0.6, 0.668, 1.0)\n",
    "#     audio_file_path = \"output\" + '.wav'\n",
    "#     sf.write(audio_file_path, audio[1], audio[0], \"PCM_16\")\n",
    "\n",
    "#     return [(history, text)],audio_file_path\n",
    "\n",
    "def ChatGPT_Bot(input,history):\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "          {\"role\": \"user\", \"content\": input}\n",
    "        ]\n",
    "    )\n",
    "    text = response['choices'][0]['message']['content']\n",
    "\n",
    "    history.append((input, text))\n",
    "\n",
    "    audio = tts_fn(text, 0.6, 0.668, 1.0)\n",
    "    audio_file_path = \"output\" + '.wav'\n",
    "    sf.write(audio_file_path, audio[1], audio[0], \"PCM_16\")\n",
    "\n",
    "    return history,audio_file_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Path):\n",
    "            return str(obj)\n",
    "        return super().default(obj)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init():\n",
    "  global SELECTED_LANGUAGE\n",
    "  SELECTED_LANGUAGE = \"JP\"\n",
    "  global SPEAKER_ID\n",
    "  SPEAKER_ID = 0\n",
    "  global COVER\n",
    "  COVER = \"models/Yuuka/cover.png\"\n",
    "  global speaker_choice\n",
    "  speaker_choice = \"Yuuka\"\n",
    "  global MODEL_ZH_NAME\n",
    "  MODEL_ZH_NAME = \"早濑优香\"\n",
    "  global EXAMPLE_TEXT\n",
    "  EXAMPLE_TEXT = \"先生。今日も全力であなたをアシストしますね。\"\n",
    "  global CONFIG_PATH\n",
    "  CONFIG_PATH = \"configs/config.json\"\n",
    "  global MODEL_PATH\n",
    "  MODEL_PATH = \"../drive/MyDrive/ML_Folder/Pytorch/Vits/G_4000.pth\"\n",
    "\n",
    "  get_options()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "download_audio_js = \"\"\"\n",
    "() =>{{\n",
    "    let root = document.querySelector(\"body > gradio-app\");\n",
    "    if (root.shadowRoot != null)\n",
    "        root = root.shadowRoot;\n",
    "    let audio = root.querySelector(\"#tts-audio-{audio_id}\").querySelector(\"audio\");\n",
    "    let text = root.querySelector(\"#input-text-{audio_id}\").querySelector(\"textarea\");\n",
    "    if (audio == undefined)\n",
    "        return;\n",
    "    text = text.value;\n",
    "    if (text == undefined)\n",
    "        text = Math.floor(Math.random()*100000000);\n",
    "    audio = audio.src;\n",
    "    let oA = document.createElement(\"a\");\n",
    "    oA.download = text.substr(0, 20)+'.wav';\n",
    "    oA.href = audio;\n",
    "    document.body.appendChild(oA);\n",
    "    oA.click();\n",
    "    oA.remove();\n",
    "}}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init()\n",
    "\n",
    "theme = gr.themes.Base()\n",
    "\n",
    "with gr.Blocks(theme=theme) as interface:\n",
    "    with gr.Tab(\"Text to Speech\"):\n",
    "        with gr.Column():\n",
    "            cover_markdown = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\"\n",
    "                                                                                           '</div>')\n",
    "            title_markdown = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>'\n",
    "                                                                                           '</div>')\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 4):\n",
    "                    input_text = gr.Textbox(\n",
    "                        label=\"Input\",\n",
    "                        lines=2,\n",
    "                        placeholder=\"Enter the text you want to process here\",\n",
    "                        elem_id=f\"input-text-en-{name_en.replace(' ','')}\",\n",
    "                        scale = 2\n",
    "                    )\n",
    "                with gr.Column(scale = 1):\n",
    "                    gen_button = gr.Button(\"Generate\", variant=\"primary\")\n",
    "                    clear_input_button = gr.Button(\"Clear\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 2):\n",
    "                    lan = gr.Radio(label=\"Language\", choices=LANGUAGES, value=\"JP\")\n",
    "                    noise_scale = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale (情感变化程度)\", value = 0.6)\n",
    "                    noise_scale_w = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale w (发音长度)\", value = 0.668)\n",
    "                    length_scale = gr.Slider(minimum=0.1, maximum=2.0, step=0.1, label = \"Length Scale (语速)\", value=1.0)\n",
    "\n",
    "                with gr.Column(scale = 1):\n",
    "                    example_text_box = gr.Textbox(label=\"Example:\",\n",
    "                                                  value=EXAMPLE_TEXT)\n",
    "\n",
    "                    output_audio = gr.Audio(label=\"Output\", elem_id=f\"tts-audio-en-{name_en.replace(' ','')}\")\n",
    "                    download_button = gr.Button(\"Download\")\n",
    "\n",
    "                    # example = gr.Examples(\n",
    "                    #     examples = [EXAMPLE_TEXT],\n",
    "                    #     inputs=input_text,\n",
    "                    #     outputs = output_audio,\n",
    "                    #     fn=example_tts_fn,\n",
    "                    #     cache_examples=True\n",
    "                    # )\n",
    "\n",
    "\n",
    "        gen_button.click(\n",
    "                    tts_fn,\n",
    "                    inputs = [input_text, noise_scale, noise_scale_w, length_scale],\n",
    "                    outputs = output_audio)\n",
    "        clear_input_button.click(\n",
    "                    clear_input_text,\n",
    "                    outputs = input_text\n",
    "        )\n",
    "        download_button.click(None, [], [], _js=download_audio_js.format(audio_id=f\"en-{name_en.replace(' ', '')}\"))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"AI Singer\"):\n",
    "      with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "          cover_markdown_vc = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\"\n",
    "                                                                                           '</div>')\n",
    "          title_markdown_vc = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>'\n",
    "                                                                                           '</div>')\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "          with gr.Row():\n",
    "            with gr.Column(scale=4):\n",
    "              vc_audio_input = gr.Audio(label=\"Input Audio\")\n",
    "            with gr.Column(scale=1):\n",
    "              vc_transform = gr.Number(label=\"Transform\",value=1.0,interactive=\"True\")\n",
    "              vc_convert_button = gr.Button(\"Convert\", variant=\"primary\")\n",
    "              vc_download_button = gr.Button(\"Download\")\n",
    "\n",
    "          with gr.Row():\n",
    "            vc_audio_output = gr.Audio(label=\"Output Audio\")\n",
    "            # vc_example = gr.Examples()\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"TTS with ChatGPT\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=7):\n",
    "                api_key = gr.Textbox(\n",
    "                    label = \"API Key\",\n",
    "                    type=\"password\")\n",
    "                api_key.change(fn=load_api_key,inputs=api_key)\n",
    "            with gr.Column(scale=1):\n",
    "                lan_ChatGPT = gr.Radio(label=\"Language\", choices=LANGUAGES, value=\"JP\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                user_input = gr.Textbox(\n",
    "                    show_label=False,\n",
    "                    placeholder=\"Enter text and press enter\")\n",
    "\n",
    "                with gr.Row():\n",
    "                    submit_button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "                    submit_clear_button = gr.Button(\"Clear\")\n",
    "\n",
    "                cover_markdown_ChatGPT = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{COVER}\">' if COVER else \"\"\n",
    "                                                                                           '</div>')\n",
    "                title_markdown_ChatGPT = gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<h3><a><strong>{\"语音名称: \"}{MODEL_ZH_NAME}</strong></a>'\n",
    "                f'<h3><strong>{\"checkpoint: \"}{speaker_choice}</strong>'\n",
    "                                                                                           '</div>')\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=650)\n",
    "                ChatGPT_Audio = gr.Audio()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        user_input.change(fn=usr_input_update, inputs=user_input)\n",
    "\n",
    "        # user_input.submit(add_text, [chatbot ,user_input], [chatbot ,user_input], queue=False).then(bot, chatbot, chatbot)\n",
    "        # user_input.submit(\n",
    "        #     ChatGPT_Bot,\n",
    "        #     inputs=user_input,\n",
    "        #     outputs=[chatbot,ChatGPT_Audio])\n",
    "\n",
    "        # submit_button.click(\n",
    "        #     fn=ChatGPT_Bot,\n",
    "        #     inputs=user_input,\n",
    "        #     outputs=[chatbot,ChatGPT_Audio])\n",
    "\n",
    "        user_input.submit(\n",
    "            ChatGPT_Bot,\n",
    "            inputs=[user_input,chatbot],\n",
    "            outputs=[chatbot,ChatGPT_Audio])\n",
    "\n",
    "        submit_button.click(\n",
    "            fn=ChatGPT_Bot,\n",
    "            inputs=[user_input,chatbot],\n",
    "            outputs=[chatbot,ChatGPT_Audio])\n",
    "\n",
    "\n",
    "        submit_clear_button.click(\n",
    "                    clear_input_text,\n",
    "                    outputs = user_input\n",
    "        )\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"Settings\"):\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"\"\"# Select Model\"\"\")\n",
    "            with gr.Row():\n",
    "\n",
    "                with gr.Column(scale = 5):\n",
    "                    model_choice = gr.Dropdown(label = \"Model\",\n",
    "                                           choices=[(model[\"name_en\"]) for name, model in models_info.items()],\n",
    "                                           interactive=True,\n",
    "                                           value=models_info['Yuuka']['name_en']\n",
    "                                         )\n",
    "                with gr.Column(scale = 5):\n",
    "                    speaker_id_choice = gr.Dropdown(label = \"Speaker ID\",\n",
    "                                         choices=[(str(model[\"sid\"])) for name, model in models_info.items()],\n",
    "                                         interactive=True,\n",
    "                                         value=str(models_info['Yuuka']['sid'])\n",
    "                                         )\n",
    "\n",
    "                with gr.Column(scale = 1):\n",
    "                    refresh_button = gr.Button(\"Refresh\", variant=\"primary\")\n",
    "                    reset_button = gr.Button(\"Reset\")\n",
    "\n",
    "        ### 切换模型功能实现\n",
    "        model_choice.change(fn=change_dropdown, inputs=model_choice, outputs=[speaker_id_choice,cover_markdown,title_markdown,lan,example_text_box,cover_markdown_ChatGPT,title_markdown_ChatGPT,lan_ChatGPT,cover_markdown_vc,title_markdown_vc])\n",
    "\n",
    "        refresh_button.click(fn=refresh_options, outputs = [model_choice,speaker_id_choice])\n",
    "        reset_button.click(reset_options, outputs = [model_choice,speaker_id_choice])\n",
    "\n",
    "\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"# Add Model\\n\"\n",
    "                        \"> *为必填选项\\n\"\n",
    "                        \"> 添加完成后将**checkpoints**文件放到对应生成的文件夹中\"\n",
    "                        )\n",
    "\n",
    "\n",
    "            with gr.Row():\n",
    "                # file = gr.Files(label = \"VITS Model*\", file_types=[\".pth\"])\n",
    "                example_text = gr.Textbox(label = \"Example Text\",\n",
    "                                          lines=16,\n",
    "                                          placeholder=\"Enter the example text here\",)\n",
    "                model_cover = gr.Image(label = \"Cover\")\n",
    "\n",
    "                with gr.Column():\n",
    "                    model_speaker_id = gr.Textbox(label = \"Speaker List*\",\n",
    "                                                  placeholder=\"Single speaker model default=0\")\n",
    "                    model_name_en = gr.Textbox(label = \"name_en*\")\n",
    "                    model_name_cn = gr.Textbox(label = \"name_cn\")\n",
    "                    model_language = gr.Dropdown(label = \"Language*\",\n",
    "                                               choices=LANGUAGES,\n",
    "                                               interactive=True)\n",
    "                    with gr.Row():\n",
    "                        add_model_button = gr.Button(\"Add Model\", variant=\"primary\")\n",
    "                        clear_add_model_button = gr.Button(\"Clear\")\n",
    "            with gr.Box():\n",
    "              with gr.Row():\n",
    "                message_box = gr.Textbox(label = \"Message\")\n",
    "\n",
    "\n",
    "\n",
    "        add_model_button.click(add_model_fn,\n",
    "                               inputs = [example_text, model_cover, model_speaker_id, model_name_en, model_name_cn, model_language],\n",
    "                               outputs = message_box\n",
    "                               )\n",
    "        clear_add_model_button.click(clear_add_model_info,\n",
    "                                     outputs = [example_text, model_cover, model_speaker_id, model_name_en, model_name_cn, model_language]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# interface.queue(concurrency_count=1).launch(debug=True)\n",
    "\n",
    "interface.launch(debug=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOanTxjuTkrY9G5Z/F1JKYD",
   "collapsed_sections": [
    "1cRKuRl7Z8Nj",
    "uYQ2esCNI4IT",
    "YvWwpaTKI5Ut",
    "1rerX8gxPmLf",
    "vs-wM321Zk0u",
    "SxpEIauJZ0s6"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
