{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cRKuRl7Z8Nj"
   },
   "source": [
    "# Requirment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ouQGqsHfsDv6",
    "outputId": "8a464347-c2ba-489e-8f45-3707e9ba2e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\AI\\VITS_WebUI\\monotonic_align\n",
      "running build_ext\n",
      "copying build\\lib.win-amd64-3.9\\monotonic_align\\core.cp39-win_amd64.pyd -> monotonic_align\n",
      "G:\\AI\\VITS_WebUI\n"
     ]
    }
   ],
   "source": [
    "%cd G:\\AI\\VITS_WebUI\\monotonic_align\n",
    "!python setup.py build_ext --inplace\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr  9 12:30:08 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.14                 Driver Version: 531.14       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060       WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   32C    P5               20W / 170W|   4662MiB / 12288MiB |     10%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1584    C+G   ...6\\Updater\\EtwHostServiceUpdater.exe    N/A      |\n",
      "|    0   N/A  N/A      2036    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A      6024    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A      6044    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      8532    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      8624    C+G   D:\\CloudMusic\\cloudmusic.exe              N/A      |\n",
      "|    0   N/A  N/A      9716    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11996    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12384    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     13440    C+G   ...rPicker\\PowerToys.ColorPickerUI.exe    N/A      |\n",
      "|    0   N/A  N/A     13468    C+G   ...FancyZones\\PowerToys.FancyZones.exe    N/A      |\n",
      "|    0   N/A  N/A     13568    C+G   ...auncher\\PowerToys.PowerLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     13660    C+G   ...0\\extracted\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     14608    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14656    C+G   D:\\Eagle\\Eagle.exe                        N/A      |\n",
      "|    0   N/A  N/A     14668    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     14760    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14832    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15576    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15604    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17068    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     17152    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A     18244    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     18308    C+G   ...03.0_x64__8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     19200    C+G   ...0.0_x64__p7pnf6hceqser\\snipaste.exe    N/A      |\n",
      "|    0   N/A  N/A     20272    C+G   D:\\Typora\\Typora.exe                      N/A      |\n",
      "|    0   N/A  N/A     22084    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     25852    C+G   ...8.0.0_x64__gqbn7fs4pywxm\\Db.App.exe    N/A      |\n",
      "|    0   N/A  N/A     25920    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     27740    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     29132    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     34788    C+G   D:\\Microsoft VS Code\\Code.exe             N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxpEIauJZ0s6"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "v10x1lO7Z5AK"
   },
   "outputs": [],
   "source": [
    "#@title  Edit config\n",
    "import json\n",
    "batchsize = 16  #@param {type:\"number\"}\n",
    "training_files = \"filelists/yuuka_train.txt.cleaned\" #@param {type:\"string\"}\n",
    "validation_files = \"filelists/yuuka_val.txt.cleaned\" #@param {type:\"string\"}\n",
    "config = json.load(open(\"configs/config.json\"))\n",
    "config['train']['batch_size'] = batchsize\n",
    "config['data']['training_files'] = training_files\n",
    "config['data']['validation_files'] = validation_files\n",
    "with open(\"configs/config.json\", 'w+') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBNba8Qpa7XF"
   },
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zF5IUSAQa_EB"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gcO8hd1Jr2t6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import commons\n",
    "import utils\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "from scipy.io.wavfile import write\n",
    "from gradio.processing_utils import download_tmp_copy_of_file\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nk7e6dxxrzWq"
   },
   "outputs": [],
   "source": [
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rCka4asRScyC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'G:\\AI\\Model\\VITS\\Yuuka\\G_4000.pth' (iteration 445)\n"
     ]
    }
   ],
   "source": [
    "config_path = \"configs/config.json\" \n",
    "model_path = \"G:\\AI\\Model\\VITS\\Yuuka\\G_4000.pth\"\n",
    "\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "net_g = SynthesizerTrn(\n",
    "    len(hps.symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "\n",
    "model = net_g.eval()\n",
    "model = utils.load_checkpoint(model_path, net_g, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tp-8n_YBg5FN"
   },
   "outputs": [],
   "source": [
    "LANGUAGES = ['EN','CN','JP']\n",
    "speaker_id = 0\n",
    "cover = \"models/Yuuka/cover.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bronya\n"
     ]
    }
   ],
   "source": [
    "with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    models_info = json.load(f)\n",
    "\n",
    "for i,model_info in models_info.items():\n",
    "    name_en = model_info['name_en']\n",
    "\n",
    "print(name_en)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(models_info['yuuka']['sid'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yxBbm6Yh8WkH"
   },
   "outputs": [],
   "source": [
    "download_audio_js = \"\"\"\n",
    "() =>{{\n",
    "    let root = document.querySelector(\"body > gradio-app\");\n",
    "    if (root.shadowRoot != null)\n",
    "        root = root.shadowRoot;\n",
    "    let audio = root.querySelector(\"#tts-audio-{audio_id}\").querySelector(\"audio\");\n",
    "    let text = root.querySelector(\"#input-text-{audio_id}\").querySelector(\"textarea\");\n",
    "    if (audio == undefined)\n",
    "        return;\n",
    "    text = text.value;\n",
    "    if (text == undefined)\n",
    "        text = Math.floor(Math.random()*100000000);\n",
    "    audio = audio.src;\n",
    "    let oA = document.createElement(\"a\");\n",
    "    oA.download = text.substr(0, 20)+'.wav';\n",
    "    oA.href = audio;\n",
    "    document.body.appendChild(oA);\n",
    "    oA.click();\n",
    "    oA.remove();\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def tts_fn(text, noise_scale, noise_scale_w, length_scale):\n",
    "  stn_tst = get_text(text, hps)\n",
    "  with torch.no_grad():\n",
    "    x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "    sid = torch.LongTensor([speaker_id]).cuda()\n",
    "    audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=noise_scale, noise_scale_w=noise_scale_w, length_scale=length_scale)[0][0,0].data.cpu().float().numpy()\n",
    "  return  (22050, audio)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, Path):\n",
    "            return str(obj)\n",
    "        return super().default(obj)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def add_model_fn(example_text, cover, SpeakerID, name_en, name_cn, language):\n",
    "\n",
    "\n",
    "\n",
    "    # 检查必填字段是否为空\n",
    "    if not speaker_id or not name_en or not language:\n",
    "        raise gr.Error(\"Please fill in all required fields!\")\n",
    "        return \"Failed to add model\"\n",
    "\n",
    "    ### 保存上传的文件\n",
    "\n",
    "    # 生成文件路径\n",
    "    model_save_dir = Path(\"models\")\n",
    "    model_save_dir = model_save_dir / name_en\n",
    "    img_save_dir = model_save_dir\n",
    "    model_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    Model_name = name_en + \".pth\"\n",
    "    model_save_dir = model_save_dir / Model_name\n",
    "\n",
    "    # 保存上传的图片\n",
    "    if cover is not None:\n",
    "        img = np.array(cover)\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(os.path.join(img_save_dir, 'cover_white_background.png'))\n",
    "\n",
    "\n",
    "\n",
    "    #获取用户输入\n",
    "    new_model = {\n",
    "        \"name_en\": name_en,\n",
    "        \"name_zh\": name_cn,\n",
    "        \"cover\": img_save_dir / \"cover.png\",\n",
    "        \"sid\": SpeakerID,\n",
    "        \"example\": \"それに新しいお菓子屋さんも出来てみんな買いものを楽しんでいます！\",\n",
    "        \"language\": language,\n",
    "        \"type\": \"single\",\n",
    "        \"model_path\": model_save_dir\n",
    "    }\n",
    "\n",
    "\n",
    "    #写入json\n",
    "    with open(\"models/model_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        models_info = json.load(f)\n",
    "\n",
    "    models_info[name_en] = new_model\n",
    "    with open(\"models/model_info.json\", \"w\") as f:\n",
    "        json.dump(models_info, f, cls=CustomEncoder)\n",
    "\n",
    "\n",
    "    return \"Success\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def clear_input_text():\n",
    "    return \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def clear_add_model_info():\n",
    "    return \"\",None,\"\",\"\",\"\",\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.reference:entering reference: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.reference:entering reference: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.heading:entering heading: StateBlock(line=0,level=0,tokens=0), 0, 1, False\n",
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.reference:entering reference: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.heading:entering heading: StateBlock(line=0,level=0,tokens=0), 0, 3, False\n",
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=1,level=0,tokens=3), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=1,level=0,tokens=3), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=1,level=0,tokens=3), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.code:entering code: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.reference:entering reference: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.heading:entering heading: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.lheading:entering lheading: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.heading:entering heading: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.paragraph:entering paragraph: StateBlock(line=1,level=1,tokens=4), 1, 3, False\n",
      "DEBUG:markdown_it.rules_block.fence:entering fence: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.blockquote:entering blockquote: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.hr:entering hr: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.list:entering list: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.html_block:entering html_block: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n",
      "DEBUG:markdown_it.rules_block.heading:entering heading: StateBlock(line=1,level=1,tokens=4), 2, 3, True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ML\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'scale': 2}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: SelectSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:7879\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:7879 \"GET /startup-events HTTP/1.1\" 200 5\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:7879\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:7879 \"HEAD / HTTP/1.1\" 200 0\n",
      "Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:httpx._client:HTTP Request: POST http://127.0.0.1:7879/api/predict \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpx._client:HTTP Request: POST http://127.0.0.1:7879/reset \"HTTP/1.1 200 OK\"\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme = gr.themes.Base()\n",
    "\n",
    "with gr.Blocks(theme=theme) as interface:\n",
    "    with gr.Tab(\"Text to Speech\"):\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\n",
    "                '<div align=\"center\">'\n",
    "                f'<img style=\"width:auto;height:512px;\" src=\"file/{cover}\">' if cover else \"\"\n",
    "                                                                                           '</div>')\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 4):\n",
    "                    input_text = gr.Textbox(\n",
    "                        label=\"Input\",\n",
    "                        lines=2,\n",
    "                        placeholder=\"Enter the text you want to process here\",\n",
    "                        elem_id=f\"input-text-en-{name_en.replace(' ','')}\",\n",
    "                        scale = 2\n",
    "                    )\n",
    "                with gr.Column(scale = 1):\n",
    "                    gen_button = gr.Button(\"Generate\", variant=\"primary\")\n",
    "                    clear_input_button = gr.Button(\"Clear\")\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale = 2):\n",
    "                    lan = [gr.Radio(label=\"Language\", choices=LANGUAGES, value=\"JP\")]\n",
    "                    noise_scale = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale (情感变化程度)\", value = 0.6)\n",
    "                    noise_scale_w = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, label = \"Noise Scale w (发音长度)\", value = 0.668)\n",
    "                    length_scale = gr.Slider(minimum=0.1, maximum=2.0, step=0.1, label = \"Length Scale (语速)\", value=1.0)\n",
    "\n",
    "                with gr.Column(scale = 1):\n",
    "                    output_audio = gr.Audio(label=\"Output\", elem_id=f\"tts-audio-en-{name_en.replace(' ','')}\")\n",
    "                    download_button = gr.Button(\"Download\")\n",
    "\n",
    "        #clear_input_button.click()\n",
    "        gen_button.click(\n",
    "                    tts_fn,\n",
    "                    inputs = [input_text, noise_scale, noise_scale_w, length_scale],\n",
    "                    outputs = output_audio)\n",
    "        clear_input_button.click(\n",
    "                    clear_input_text,\n",
    "                    outputs = input_text\n",
    "        )\n",
    "        download_button.click(None, [], [], _js=download_audio_js.format(audio_id=f\"en-{name_en.replace(' ', '')}\"))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"AI Singer\"):\n",
    "        input_text_singer = gr.Textbox()\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"TTS with ChatGPT\"):\n",
    "        input_text_gpt = gr.Textbox()\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "    with gr.Tab(\"Settings\"):\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"\"\"# Select Model\"\"\")\n",
    "            with gr.Row():\n",
    "\n",
    "                with gr.Column(scale = 5):\n",
    "                    model_choice = gr.Dropdown(label = \"Model\",\n",
    "                                           choices=[(model[\"name_en\"]) for name, model in models_info.items()],\n",
    "                                           interactive=True,\n",
    "                                           value=models_info['yuuka']['name_en']\n",
    "                                         )\n",
    "                with gr.Column(scale = 5):\n",
    "                    speaker_id = gr.Dropdown(label = \"Speaker ID\",\n",
    "                                         choices=[(str(model[\"sid\"])) for name, model in models_info.items()],\n",
    "                                         interactive=True,\n",
    "                                         value=str(models_info['yuuka']['sid'])\n",
    "                                         )\n",
    "\n",
    "                with gr.Column(scale = 1):\n",
    "                    refresh_button = gr.Button(\"Refresh\", variant=\"primary\")\n",
    "                    reset_button = gr.Button(\"Reset\")\n",
    "\n",
    "        with gr.Box():\n",
    "            gr.Markdown(\"# Add Model\\n\"\n",
    "                        \"> *为必填选项\\n\"\n",
    "                        \"> 添加完成后将**checkpoints**文件放到对应生成的文件夹中\"\n",
    "                        )\n",
    "\n",
    "\n",
    "            with gr.Row():\n",
    "                # file = gr.Files(label = \"VITS Model*\", file_types=[\".pth\"])\n",
    "                example_text = gr.Textbox(label = \"Example Text\",\n",
    "                                          lines=16,\n",
    "                                          placeholder=\"Enter the example text here\",)\n",
    "                model_cover = gr.Image(label = \"Cover\")\n",
    "\n",
    "                with gr.Column():\n",
    "                    model_speaker_id = gr.Textbox(label = \"Speaker List*\",\n",
    "                                                  placeholder=\"Single speaker model default=0\")\n",
    "                    model_name_en = gr.Textbox(label = \"name_en*\")\n",
    "                    model_name_cn = gr.Textbox(label = \"name_cn\")\n",
    "                    model_language = gr.Dropdown(label = \"Language*\",\n",
    "                                               choices=LANGUAGES,\n",
    "                                               interactive=True)\n",
    "                    with gr.Row():\n",
    "                        add_model_button = gr.Button(\"Add Model\", variant=\"primary\")\n",
    "                        clear_add_model_button = gr.Button(\"Clear\")\n",
    "            with gr.Box():\n",
    "              with gr.Row():\n",
    "                message_box = gr.Textbox(label = \"Message\")\n",
    "\n",
    "\n",
    "\n",
    "        add_model_button.click(add_model_fn,\n",
    "                               inputs = [example_text, model_cover, model_speaker_id, model_name_en, model_name_cn, model_language],\n",
    "                               outputs = message_box\n",
    "                               )\n",
    "        clear_add_model_button.click(clear_add_model_info,\n",
    "                                     outputs = [example_text, model_cover, model_speaker_id, model_name_en, model_name_cn, model_language]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interface.queue(concurrency_count=1).launch(debug=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOanTxjuTkrY9G5Z/F1JKYD",
   "collapsed_sections": [
    "1cRKuRl7Z8Nj",
    "uYQ2esCNI4IT",
    "YvWwpaTKI5Ut",
    "1rerX8gxPmLf",
    "vs-wM321Zk0u",
    "SxpEIauJZ0s6"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
